<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.15" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <title>Vicky's Notes</title><meta name="description" content="Collection">
    <link rel="preload" href="/tools/assets/style-DY6JTdq5.css" as="style"><link rel="stylesheet" href="/tools/assets/style-DY6JTdq5.css">
    <link rel="modulepreload" href="/tools/assets/app-ZAevFdOi.js"><link rel="modulepreload" href="/tools/assets/02_ollama.html-D09TRoOW.js">
    <link rel="prefetch" href="/tools/assets/index.html-DUIhoUSO.js" as="script"><link rel="prefetch" href="/tools/assets/01_Course.html-BUUty9vS.js" as="script"><link rel="prefetch" href="/tools/assets/01_src.html-BKTwChUj.js" as="script"><link rel="prefetch" href="/tools/assets/Chapter01.html-hmR-yXpn.js" as="script"><link rel="prefetch" href="/tools/assets/env.html-q2FfFCV9.js" as="script"><link rel="prefetch" href="/tools/assets/python_env.html-CGjrsg0d.js" as="script"><link rel="prefetch" href="/tools/assets/solidity.html-lfZvnUzG.js" as="script"><link rel="prefetch" href="/tools/assets/Tools.html-Uxj4WZfd.js" as="script"><link rel="prefetch" href="/tools/assets/source.html-BR5bblDw.js" as="script"><link rel="prefetch" href="/tools/assets/01_env.html-mwgVHrTo.js" as="script"><link rel="prefetch" href="/tools/assets/Linux.html-adGDoOlL.js" as="script"><link rel="prefetch" href="/tools/assets/Daily_Tools.html-BiZSxYuZ.js" as="script"><link rel="prefetch" href="/tools/assets/01_env.html-BPYY1wta.js" as="script"><link rel="prefetch" href="/tools/assets/x.html-C0G1ZQBg.js" as="script"><link rel="prefetch" href="/tools/assets/01.html-DL3G0Une.js" as="script"><link rel="prefetch" href="/tools/assets/01.html-Sx8OnlAW.js" as="script"><link rel="prefetch" href="/tools/assets/02.html-CZlLREpR.js" as="script"><link rel="prefetch" href="/tools/assets/01.html-BwNWQRb2.js" as="script"><link rel="prefetch" href="/tools/assets/01_Thoughts.html-DktI0DMk.js" as="script"><link rel="prefetch" href="/tools/assets/01_Tools.html-pJ65toTd.js" as="script"><link rel="prefetch" href="/tools/assets/Books.html-itZ0dXrc.js" as="script"><link rel="prefetch" href="/tools/assets/Go.html-CNGSU2jr.js" as="script"><link rel="prefetch" href="/tools/assets/product.html-sWjeafv1.js" as="script"><link rel="prefetch" href="/tools/assets/Old.html-BdZVILZe.js" as="script"><link rel="prefetch" href="/tools/assets/blockchain.html-DlhTdiMu.js" as="script"><link rel="prefetch" href="/tools/assets/ignite.html-Bao8gByc.js" as="script"><link rel="prefetch" href="/tools/assets/index.html-MmliBUe9.js" as="script"><link rel="prefetch" href="/tools/assets/404.html-LmIPBqEs.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container no-navbar external-link-icon" vp-container><!--[--><!----><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><!----><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading">Collection <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/tools/" aria-label="General"><!---->General<!----></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading">System <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/tools/System/Old.html" aria-label="Old System"><!---->Old System<!----></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading">Raspberry <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/tools/Raspberry/01.html" aria-label="Raspberry Hardware Info"><!---->Raspberry Hardware Info<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/tools/Raspberry/02.html" aria-label="/Raspberry/02.html"><!---->/Raspberry/02.html<!----></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading">Daily <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/tools/General/Daily_Tools.html" aria-label="Daily Tools"><!---->Daily Tools<!----></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading">Resource <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/tools/C/source.html" aria-label="逆向"><!---->逆向<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/tools/Resource/Books.html" aria-label="Book"><!---->Book<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item" href="/tools/Test/blockchain.html" aria-label="BlockChain"><!---->BlockChain<!----></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading">Environment <!----></p><ul style="" class="vp-sidebar-children"><!--[--><li><a class="route-link auto-link vp-sidebar-item" href="/tools/Env/Linux.html" aria-label="Linux"><!---->Linux<!----></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h2 id="python" tabindex="-1"><a class="header-anchor" href="#python"><span>Python</span></a></h2><ul><li><a href="https://kinsta.com/knowledgebase/install-python/" target="_blank" rel="noopener noreferrer">install python</a></li></ul><h2 id="ollama" tabindex="-1"><a class="header-anchor" href="#ollama"><span>Ollama</span></a></h2><ul><li><a href="https://ollama.com/library" target="_blank" rel="noopener noreferrer">library</a></li><li><a href="https://github.com/ollama/ollama/blob/main/docs/api.md" target="_blank" rel="noopener noreferrer">github - api doc</a></li><li><a href="https://msty.app/" target="_blank" rel="noopener noreferrer">msty - UI</a></li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">ollama list</span>
<span class="line"></span>
<span class="line">ollama run llama3.2</span>
<span class="line"></span>
<span class="line">/clear</span>
<span class="line"></span>
<span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> /help</span>
<span class="line">Available Commands:</span>
<span class="line">  /set            Set session variables</span>
<span class="line">  /show           Show model information</span>
<span class="line">  /load <span class="token operator">&lt;</span>model<span class="token operator">&gt;</span>   Load a session or model</span>
<span class="line">  /save <span class="token operator">&lt;</span>model<span class="token operator">&gt;</span>   Save your current session</span>
<span class="line">  /clear          Clear session context</span>
<span class="line">  /bye            Exit</span>
<span class="line">  /?, /help       Help <span class="token keyword">for</span> a <span class="token builtin class-name">command</span></span>
<span class="line">  /? shortcuts    Help <span class="token keyword">for</span> keyboard shortcuts</span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="show-info" tabindex="-1"><a class="header-anchor" href="#show-info"><span>show info</span></a></h3><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> /show info</span>
<span class="line">  Model</span>
<span class="line">    architecture        llama</span>
<span class="line">    parameters          <span class="token number">3</span>.2B</span>
<span class="line">    context length      <span class="token number">131072</span></span>
<span class="line">    embedding length    <span class="token number">3072</span></span>
<span class="line">    quantization        Q4_K_M</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol><li>Model Architecture (模型架构) llama —— 该模型基于 LLaMA (Large Language Model Meta AI) 架构，这是一种由 Meta (Facebook) 开发的高级大语言模型架构，优化了推理能力和计算效率。 The model is based on the LLaMA (Large Language Model Meta AI) architecture, developed by Meta (Facebook). It is optimized for inference capabilities and computational efficiency.</li><li>Parameters (参数数量) 3.2B —— 该模型拥有 3.2 billion (32 亿) 个参数，参数越多通常意味着更强的理解能力，但也增加了计算资源的需求。 The model has 3.2 billion parameters. More parameters generally lead to better understanding but require more computational resources.</li><li>Context Length (上下文长度) 131072 —— 该模型支持 131,072 个 token 的上下文窗口，表示它可以在单次处理过程中记住更长的对话历史或文档内容。 The model supports a context window of 131,072 tokens, meaning it can remember a longer conversation history or document in a single process.</li><li>Embedding Length (嵌入向量长度) 3072 —— 该模型的词向量（embedding）长度为 3072 维，用于将文本转换为高维数值表示，以便进行计算和推理。 The model has an embedding size of 3072 dimensions, which represents how words are transformed into high-dimensional numerical representations for computation and reasoning.</li><li>Quantization (量化方式) Q4_K_M —— 该模型采用 Q4_K_M 量化，这是一种 4-bit 量化技术，能够在降低存储需求和计算成本的同时保持较高的推理精度。 The model uses Q4_K_M quantization, a 4-bit quantization technique that reduces storage and computation costs while maintaining high inference accuracy.</li></ol><h2 id="python-env" tabindex="-1"><a class="header-anchor" href="#python-env"><span>Python env</span></a></h2><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">pip3 <span class="token function">install</span> ollama</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><!----></div></footer><!----><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/tools/assets/app-ZAevFdOi.js" defer></script>
  </body>
</html>
